{"hash":"a12e502c9392790ed2b6909ce3e2f6ba93e467c2","data":{"markdownPage":{"id":"1350dc749ae56e0a7dcd0be3046a48dd","title":"","description":"","path":"/tool/deepseek-ai/","timeToRead":3,"content":"<!-- <h1>구내 설치형 AI기반 분석설계 및 구현, 배포<br>(MSAEZ + DeepSeek)</h1> -->\n<h1 id=\"msaez에서-deepseek-모델-활용-가이드-runpod-클라우드-gpu-환경\"><a href=\"#msaez%EC%97%90%EC%84%9C-deepseek-%EB%AA%A8%EB%8D%B8-%ED%99%9C%EC%9A%A9-%EA%B0%80%EC%9D%B4%EB%93%9C-runpod-%ED%81%B4%EB%9D%BC%EC%9A%B0%EB%93%9C-gpu-%ED%99%98%EA%B2%BD\" aria-hidden=\"true\"><span class=\"icon icon-link\"></span></a>MSAEZ에서 DeepSeek 모델 활용 가이드 (RunPod 클라우드 GPU 환경)</h1>\n<p><strong>MSAEZ</strong>가 <strong>DeepSeek AI</strong> 추론 모델을 Private한 클라우드 환경에서 직접 활용할 수 있도록 지원합니다.</p>\n<p><strong>DeepSeek 모델</strong>은 7B, 67B 등 다양한 매개변수 크기로 제공되며, 2조 토큰 이상의 방대한 데이터로 훈련되었습니다. 이 데이터에는 코드, 수학 문제, 일반 텍스트 등이 포함되어 있어 다양한 분야에서 활용할 수 있습니다. 특히 주목할 만한 점은 대부분의 모델이 MIT나 Apache 2.0 라이선스 하에 오픈소스로 공개되어 있다는 것입니다.</p>\n<p><strong>Ollama</strong> 도구를 활용하여 DeepSeek AI 모델을 로컬 환경에 직접 설치하고 이를 활용함으로써, 클라우드 기반 AI 서비스의 비용과 의존성을 줄이고 온프레미스 환경에서도 AI 기능을 자유롭게 사용할 수 있습니다.</p>\n<p>특히, DeepSeek AI를 활용해 요구사항을 분석하고, 도메인 주도 설계(DDD) 기반의 클라우드 네이티브 모델링을 설계자와 소통(Human-in-the-loop)하며 최적화할 수 있어, 더욱 정교한 마이크로서비스 아키텍처를 구축할 수 있으며, 데이터 일관성을 확보하면서도 유연한 설계가 가능해졌습니다.</p>\n<p>이 가이드는 <strong>MSAEZ 사용자가 DeepSeek AI 모델을 RunPod 클라우드 GPU 환경에서 실행하고 MSAEZ와 연동하여 사용하는 방법</strong>을 안내합니다. MSAEZ를 활용하여 AI 기반 마이크로서비스를 구축하고자 하는 개발자를 대상으로 합니다.\n<br><br></p>\n<!-- ## MSAEZ MSA 개발 프로세스\n\n<img src=\"https://github.com/user-attachments/assets/5fe9e0c5-064f-4969-ad9e-5389196f08f6\">\n<br>\nMSAEZ는 도메인 분석을 통해 마이크로서비스를 도출하고, 헥사고날 및 이벤트 드리븐 아키텍처 기반으로 설계한 후, 자동화된 테스트와 CI/CD 배포를 통해 안정적인 MSA 개발을 지원하는 전 주기에 걸친 프로세스를 제공합니다. \n<br><br>\n\n## 온프레미스 AI를 활용한 마이크로서비스 설계/구현/배포\n\n<img src=\"https://github.com/user-attachments/assets/b2851b91-543c-47a4-82d7-335ea0b1baa7\">\n<br>\nMSAEZ는 온프레미스 DeepSeek AI 모델을 활용하여 마이크로서비스를 자동 생성하고, 프로덕션 환경과 연동하여 마이크로서비스 설계를 자동화하고, AI를 활용한 자동화된 마이크로서비스 아키텍처 구축을 지원하여, 보다 효율적인 MSA 환경 도입을 가능하게 합니다. \n<br><br> -->\n<h2 id=\"클라우드-gpu-서비스를-활용한-deepseek-환경-구성\"><a href=\"#%ED%81%B4%EB%9D%BC%EC%9A%B0%EB%93%9C-gpu-%EC%84%9C%EB%B9%84%EC%8A%A4%EB%A5%BC-%ED%99%9C%EC%9A%A9%ED%95%9C-deepseek-%ED%99%98%EA%B2%BD-%EA%B5%AC%EC%84%B1\" aria-hidden=\"true\"><span class=\"icon icon-link\"></span></a>클라우드 GPU 서비스를 활용한 DeepSeek 환경 구성</h2>\n<h3 id=\"runpod를-활용한-deepseek-모델-환경-설정\"><a href=\"#runpod%EB%A5%BC-%ED%99%9C%EC%9A%A9%ED%95%9C-deepseek-%EB%AA%A8%EB%8D%B8-%ED%99%98%EA%B2%BD-%EC%84%A4%EC%A0%95\" aria-hidden=\"true\"><span class=\"icon icon-link\"></span></a>RunPod를 활용한 DeepSeek 모델 환경 설정</h3>\n<p><strong>1. <a href=\"https://runpod.io/\" target=\"_blank\" rel=\"noopener noreferrer\">RunPod</a>의 Pods 메뉴를 통해서 새로운 Pod를 만들어서 요청할 수 있습니다.</strong></p>\n<img style=\"margin-top: -20px;\" src=\"https://github.com/user-attachments/assets/8c1c8845-c031-4cb4-8cbb-596acc79fe47\">\n<ul>\n<li>현재 사용하려고 하는 <code>deepseek-ai/DeepSeek-R1-Distill-Qwen-32B</code> 모델에는 최소 80GB 이상의 VM을 세팅해야 합니다.</li>\n<li>커뮤니티 클라우드, 시큐어 클라우드가 있으며, 현재 시큐어 클라우드는 불안정한 부분이 있기 때문에 <strong>커뮤니티 클라우드</strong> 사용을 권장합니다.</li>\n<li>아키텍쳐는 <code>4x RTX 4000 Ada</code> 를 권장하며, 선택이 불가능할 경우 유사한 성능의 인스턴스를 선택합니다.\n<br><br></li>\n</ul>\n<p><strong>2. Edit Templdate을 눌러 템플릿을 설정합니다.</strong></p>\n<img src=\"https://github.com/user-attachments/assets/a39f6e9a-0651-4e58-96c7-74a45cf95c99\">\n<br>\n<img src=\"https://github.com/user-attachments/assets/c155ff28-3f51-47d0-96d7-e12952e6a8d9\">\n<ul>\n<li>\n<p>템플릿 설정인 경우, <code>Qwen 2.5 Coder 32B - SGLang by Relis</code>와 같은 SGLang 베이스가 안정적입니다.</p>\n<ul>\n<li><code>--tensor-parallel-size</code>는 텐서 병렬 처리를 활성화하며, 모델을 몇 개의 GPU에 분산하여 로드할지를 결정합니다. 이는 단일 GPU 메모리 용량 제한을 극복하고, 병렬 처리를 통해 추론 속도를 향상시킬 수 있습니다. 일반적으로 최적의 값은 <strong>사용 가능한 GPU 인스턴스 개수와 일치시키는 것</strong>입니다. 예를 들어 4개의 RTX 4000 Ada GPU 인스턴스를 사용하는 경우 --tensor-parallel-size 4 로 설정합니다.</li>\n<li><code>--mem-fraction-static</code>은 <strong>GPU 메모리 중 얼마만큼을 모델 실행 전에 미리 정적으로 확보할지를 비율로 설정하는 파라미터</strong>입니다. GPU 메모리는 동적으로 할당될 수도 있지만, 긴 컨텍스트 사이즈가 전달될 경우 메모리 부족 에러가 발생하기 쉽습니다. 이러한 경우를 대비하여 지정된 비율만큼 메모리를 미리 점유하도록 설정합니다. <strong>일반적으로 0.8~0.9 정도를 시작 값으로 설정</strong>하고, <strong>모델 크기, 컨텍스트 길이, GPU 메모리 상황 등을 고려하여 조정</strong>하는 것이 좋습니다.</li>\n</ul>\n</li>\n</ul>\n<pre class=\"language-bash\"><code class=\"language-bash\">python3 <span class=\"token parameter variable\">-m</span> sglang.launch_server --model-path deepseek-ai/DeepSeek-R1-Distill-Qwen-32B --context-length <span class=\"token number\">131072</span> <span class=\"token parameter variable\">--host</span> <span class=\"token number\">0.0</span>.0.0 <span class=\"token parameter variable\">--port</span> <span class=\"token number\">8000</span> --tensor-parallel-size 사용된 인스턴스의 GPU 수 --api-key LLM 요청시 사용 할 API 키 --mem-fraction-static <span class=\"token number\">0.9</span> --disable-cuda-graph</code></pre>\n<img src=\"https://github.com/user-attachments/assets/92598e42-caa6-4977-9912-557914ee322f\">\n<br>\n<img src=\"https://github.com/user-attachments/assets/93c4499b-51a6-4ba5-9248-d7e3a9ccd1f0\">\n<ul>\n<li>Volume Disk는 현재 사용 할 모델인 Qwen 2.5 Coder 32B에 대한 모델 캐싱 및 여러 설정 파일을 고려해서 90GB 정도를 시작 용량으로 할당할 수 있습니다.</li>\n<li>서비스 중단 없는 안정적인 운영을 위해서 On-Demand로 설정합니다.\n<br><br></li>\n</ul>\n<h3 id=\"deepseek모델-설정-확인\"><a href=\"#deepseek%EB%AA%A8%EB%8D%B8-%EC%84%A4%EC%A0%95-%ED%99%95%EC%9D%B8\" aria-hidden=\"true\"><span class=\"icon icon-link\"></span></a>DeepSeek모델 설정 확인</h3>\n<h4 id=\"로그-확인하기\"><a href=\"#%EB%A1%9C%EA%B7%B8-%ED%99%95%EC%9D%B8%ED%95%98%EA%B8%B0\" aria-hidden=\"true\"><span class=\"icon icon-link\"></span></a>로그 확인하기</h4>\n<img src=\"https://github.com/user-attachments/assets/73b97cce-9619-4739-80c5-039cf2d7ed23\">\n<br>\n<img src=\"https://github.com/user-attachments/assets/7d25d7fa-0b86-4159-b2ad-dbb23c1e2719\">\n<ul>\n<li><code>Log > Container</code>로 로그를 확인합니다.</li>\n<li><code>The server is fired up and ready to roll</code>: 실제로 쓸 수 있게 되는 시점\n<br><br>\n</li>\n</ul>\n<h4 id=\"접속하기\"><a href=\"#%EC%A0%91%EC%86%8D%ED%95%98%EA%B8%B0\" aria-hidden=\"true\"><span class=\"icon icon-link\"></span></a>접속하기</h4>\n<img src=\"https://github.com/user-attachments/assets/b26e1608-85b2-42df-9e08-0e6a9439a700\">\n<br>\n<ul>\n<li><code>Connext > HTTP Service</code></li>\n<li>접속 URL은 올려진 Pod에 들어가는 경로입니다.</li>\n</ul>\n<pre class=\"language-bash\"><code class=\"language-bash\">https <span class=\"token parameter variable\">-v</span> POST <span class=\"token operator\">&lt;</span>요청 Pod URL<span class=\"token operator\">></span>/v1/chat/completions <span class=\"token punctuation\">\\</span>\n  Authorization:<span class=\"token string\">\"Bearer &lt;LLM 요청시 사용 할 API 키>\"</span> <span class=\"token punctuation\">\\</span>\n  <span class=\"token assign-left variable\">model</span><span class=\"token operator\">=</span><span class=\"token string\">\"deepseek-ai/DeepSeek-R1-Distill-Qwen-32B\"</span> <span class=\"token punctuation\">\\</span>\n  messages:<span class=\"token operator\">=</span><span class=\"token string\">'[{\"role\": \"user\", \"content\": \"프랑스의 수도는 어디야?\"}]'</span></code></pre>\n<p><br><br></p>\n<h2 id=\"msaez에서-runpod기반-deepseek-모델을-사용하기-위한-설정\"><a href=\"#msaez%EC%97%90%EC%84%9C-runpod%EA%B8%B0%EB%B0%98-deepseek-%EB%AA%A8%EB%8D%B8%EC%9D%84-%EC%82%AC%EC%9A%A9%ED%95%98%EA%B8%B0-%EC%9C%84%ED%95%9C-%EC%84%A4%EC%A0%95\" aria-hidden=\"true\"><span class=\"icon icon-link\"></span></a>MSAEZ에서 RunPod기반 DeepSeek 모델을 사용하기 위한 설정</h2>\n<p>MSAEZ는 DeepSeek 모델을 다양한 용도로 활용하기 위해 complexModel, standardModel, simpleModel 세 가지 모델 설정을 제공합니다.</p>\n<ul>\n<li><code>complexModel</code>: 정책 생성과 같이 복잡하고 높은 성능을 요구하는 작업에 사용됩니다.</li>\n<li><code>standardModel</code>: 대부분의 일반적인 AI 기능 (예: 텍스트 생성, 질의 응답 등)에 사용됩니다. MSAEZ의 핵심 AI 기능은 <code>standardModel</code>을 통해 제공됩니다.</li>\n<li><code>simpleModel</code>: JSON 객체 오류 수정과 같이 비교적 간단하고 빠른 처리가 필요한 작업에 사용됩니다.\n<br><br></li>\n</ul>\n<p><strong>1. 관련 Proxy 서버를 실행합니다.</strong></p>\n<ul>\n<li><code>server.js</code> Proxy 서버는 MSAEZ와 RunPod 간의 원활한 통신을 중계하며, MSAEZ는 위에서 설명된 모델 설정을 통해 다양한 AI 기능을 효율적으로 제공합니다.</li>\n</ul>\n<pre class=\"language-bash\"><code class=\"language-bash\"><span class=\"token function\">node</span> ./server.js</code></pre>\n<p><strong>2. localStorage를 값을 변경해서 관련 모델을 사용하도록 만듭니다.</strong></p>\n<pre class=\"language-js\"><code class=\"language-js\"><span class=\"token dom variable\">localStorage</span><span class=\"token punctuation\">.</span><span class=\"token property-access\">complexModel</span> <span class=\"token operator\">=</span> <span class=\"token string\">\"deepseek-ai/DeepSeek-R1-Distill-Qwen-32B\"</span>\n<span class=\"token dom variable\">localStorage</span><span class=\"token punctuation\">.</span><span class=\"token property-access\">standardModel</span> <span class=\"token operator\">=</span> <span class=\"token string\">\"deepseek-ai/DeepSeek-R1-Distill-Qwen-32B\"</span>\n<span class=\"token dom variable\">localStorage</span><span class=\"token punctuation\">.</span><span class=\"token property-access\">simpleModel</span> <span class=\"token operator\">=</span> <span class=\"token string\">\"deepseek-ai/DeepSeek-R1-Distill-Qwen-32B\"</span>\n<span class=\"token dom variable\">localStorage</span><span class=\"token punctuation\">.</span><span class=\"token property-access\">runpodUrl</span> <span class=\"token operator\">=</span> <span class=\"token string\">\"&lt;요청 Pod URL>/v1/chat/completions\"</span></code></pre>\n<img src=\"https://github.com/user-attachments/assets/afa73078-4398-4187-979a-e789c75a574b\">\n<br>\n<p><strong>3. 테스트 완료시, 기존 디폴트 모델 사용을 위해서 다시 빈 값으로 초기화합니다.</strong></p>\n<pre class=\"language-js\"><code class=\"language-js\"><span class=\"token dom variable\">localStorage</span><span class=\"token punctuation\">.</span><span class=\"token property-access\">complexModel</span> <span class=\"token operator\">=</span> <span class=\"token string\">\"\"</span>\n<span class=\"token dom variable\">localStorage</span><span class=\"token punctuation\">.</span><span class=\"token property-access\">standardModel</span> <span class=\"token operator\">=</span> <span class=\"token string\">\"\"</span>\n<span class=\"token dom variable\">localStorage</span><span class=\"token punctuation\">.</span><span class=\"token property-access\">simpleModel</span> <span class=\"token operator\">=</span> <span class=\"token string\">\"\"</span></code></pre>\n<p><br><br></p>\n<h2 id=\"구내-설치형-ai기반-분석설계-및-구현-배포-msaez--deepseek\"><a href=\"#%EA%B5%AC%EB%82%B4-%EC%84%A4%EC%B9%98%ED%98%95-ai%EA%B8%B0%EB%B0%98-%EB%B6%84%EC%84%9D%EC%84%A4%EA%B3%84-%EB%B0%8F-%EA%B5%AC%ED%98%84-%EB%B0%B0%ED%8F%AC-msaez--deepseek\" aria-hidden=\"true\"><span class=\"icon icon-link\"></span></a>구내 설치형 AI기반 분석설계 및 구현, 배포 (MSAEZ + DeepSeek)</h2>\n<h3 id=\"deepseek-r1-distill-qwen-32b-모델을-적용한-데모-애플리케이션---민원신청-시연\"><a href=\"#deepseek-r1-distill-qwen-32b-%EB%AA%A8%EB%8D%B8%EC%9D%84-%EC%A0%81%EC%9A%A9%ED%95%9C-%EB%8D%B0%EB%AA%A8-%EC%95%A0%ED%94%8C%EB%A6%AC%EC%BC%80%EC%9D%B4%EC%85%98---%EB%AF%BC%EC%9B%90%EC%8B%A0%EC%B2%AD-%EC%8B%9C%EC%97%B0\" aria-hidden=\"true\"><span class=\"icon icon-link\"></span></a><code>DeepSeek-R1-Distill-Qwen-32B</code> 모델을 적용한 데모 애플리케이션 - 민원신청 시연</h3>\n<div style=\"position: relative; padding-bottom: 56.25%; padding-top: 0px; height: 0; overflow: hidden;\">\n\t<iframe style=\"position: absolute; top: 0; left: 0; width: 100%; height: 100%;\" \n        src=\"https://www.youtube.com/embed/4PX4CWrdGCg?si=oD969pF_VGUpSf4Q&amp;start=3652\" \n        frameborder=\"0\" crolling=\"no\" frameborder=\"none\" allowfullscreen=\"\">\n    </iframe>\n</div>\n","sidebar":"started","next":"","prev":"","headings":[{"depth":1,"value":"MSAEZ에서 DeepSeek 모델 활용 가이드 (RunPod 클라우드 GPU 환경)","anchor":"#msaez에서-deepseek-모델-활용-가이드-runpod-클라우드-gpu-환경"},{"depth":2,"value":"클라우드 GPU 서비스를 활용한 DeepSeek 환경 구성","anchor":"#클라우드-gpu-서비스를-활용한-deepseek-환경-구성"},{"depth":3,"value":"RunPod를 활용한 DeepSeek 모델 환경 설정","anchor":"#runpod를-활용한-deepseek-모델-환경-설정"},{"depth":3,"value":"DeepSeek모델 설정 확인","anchor":"#deepseek모델-설정-확인"},{"depth":4,"value":"로그 확인하기","anchor":"#로그-확인하기"},{"depth":4,"value":"접속하기","anchor":"#접속하기"},{"depth":2,"value":"MSAEZ에서 RunPod기반 DeepSeek 모델을 사용하기 위한 설정","anchor":"#msaez에서-runpod기반-deepseek-모델을-사용하기-위한-설정"},{"depth":2,"value":"구내 설치형 AI기반 분석설계 및 구현, 배포 (MSAEZ + DeepSeek)","anchor":"#구내-설치형-ai기반-분석설계-및-구현-배포-msaez--deepseek"},{"depth":3,"value":"DeepSeek-R1-Distill-Qwen-32B 모델을 적용한 데모 애플리케이션 - 민원신청 시연","anchor":"#deepseek-r1-distill-qwen-32b-모델을-적용한-데모-애플리케이션---민원신청-시연"}]},"allMarkdownPage":{"edges":[{"node":{"path":"/tool/si-gpt/","title":"Code Implementation with ChatGPT"}},{"node":{"path":"/tool/setup-on-prem/","title":"Running on Docker Compose (with Github)"}},{"node":{"path":"/tool/plsql-2-java/","title":"Legacy Modernizer"}},{"node":{"path":"/tool/pbc-marketplace/","title":"Composable Enterprise Implementation for PBCs(Packaged Business Capabilities)"}},{"node":{"path":"/tool/on-prem-inst/","title":"Installing on-premise MSA-Easy"}},{"node":{"path":"/tool/on-prem-inst-gitea/","title":"on-prem 설치 설명서"}},{"node":{"path":"/tool/model-driven/","title":"Code Generation"}},{"node":{"path":"/tool/marketplace/","title":"Marketplace"}},{"node":{"path":"/tool/k8s-modeling/","title":"K8s Deployment Modeling"}},{"node":{"path":"/tool/infrastructure-modeling/","title":"Infrastructure Modeling (Kubernetes)"}},{"node":{"path":"/tool/event-storming-tool/","title":"EventStorming"}},{"node":{"path":"/tool/google-drive-examples/","title":"Google Drive Examples"}},{"node":{"path":"/tool/event-monitoring/","title":"Event Monitoring"}},{"node":{"path":"/tool/development-practice/","title":"Registration Course"}},{"node":{"path":"/tool/deepseek-ai/","title":""}},{"node":{"path":"/tool/cloud-ide-tool/","title":"Cloud IDE"}},{"node":{"path":"/tool/ddl-to-eventstorming/","title":"DDL To EventStorming"}},{"node":{"path":"/tool/bc-domain-gen/","title":"자연어 기반 Bounded Context & 도메인 설계 AI"}},{"node":{"path":"/tool/chat-gpt/","title":"Creating Models with ChatGPT"}},{"node":{"path":"/tool/attending-lectures/","title":"Attending lectures"}},{"node":{"path":"/tool/aggregate-design/","title":"애그리거트(Aggregate) 설계"}},{"node":{"path":"/templates-language/springboot-java-template/","title":"Spring Boot/Java Template"}},{"node":{"path":"/templates-language/python-template/","title":"Python template "}},{"node":{"path":"/templates-language/go-template/","title":"Go Template "}},{"node":{"path":"/started/event-storming-learning/","title":"Event Storming Learning"}},{"node":{"path":"/started/key-features/","title":"Key Features"}},{"node":{"path":"/started/","title":"Introduction"}},{"node":{"path":"/started/domain-driven/","title":"Domain-Driven Design Learning"}},{"node":{"path":"/operation/ops-deploy-diagramming-basic-objects/","title":"12st Mall Basic Deploy"}},{"node":{"path":"/operation/ops-deploy-diagramming-advanced-ingress/","title":"Ingress Deployment Model Design"}},{"node":{"path":"/operation/ops-deploy-diagramming-advanced-pvc/","title":"Persistent Volume"}},{"node":{"path":"/operation/ops-deploy-diagramming-advanced-istio/","title":"Istio Mesh"}},{"node":{"path":"/operation/ops-deploy-diagramming-advanced-hpa/","title":"Automatic Scaling (HPA) Deployment"}},{"node":{"path":"/info/pricing/","title":"Pricing"}},{"node":{"path":"/info/partnership/","title":"Partner Program"}},{"node":{"path":"/info/company/","title":"Cases"}},{"node":{"path":"/example-scenario/online-lecture/","title":"Internet lecture system"}},{"node":{"path":"/example-scenario/animal-hospital/","title":"Veterinary Practice Management System"}},{"node":{"path":"/example-scenario/food-delivery/","title":"food delivery"}},{"node":{"path":"/example-scenario/library-system/","title":"library system"}},{"node":{"path":"/example-scenario/accommodation-reservation/","title":"AirBnB"}},{"node":{"path":"/development/pub-sub/","title":"Pub/Sub Integration"}},{"node":{"path":"/development/oauth2with-keycloak/","title":"JWT Token-based Authentication and Authorization"}},{"node":{"path":"/development/monolith-2-misvc/","title":"Request/Response Communication in MSA Integration"}},{"node":{"path":"/development/gateway/","title":"API Gateway"}},{"node":{"path":"/development/dp-cqrs/","title":"Data Projection with CQRS"}},{"node":{"path":"/development/cna-start/","title":"Running Unit Microservices"}},{"node":{"path":"/development/choreography-saga/","title":"Choreography Saga"}},{"node":{"path":"/custom-template/unit-test/","title":"Test Automation"}},{"node":{"path":"/custom-template/template-editor/","title":"Template Editor"}},{"node":{"path":"/custom-template/tutorial/","title":"Concept of Custom Template"}},{"node":{"path":"/custom-template/template-structure/","title":"Template File Structure"}},{"node":{"path":"/custom-template/template-editor-custom-template/","title":"Creating Custom Templates in MSAEZ"}},{"node":{"path":"/custom-template/mock-server/","title":"Open API 3.0-based Mock Server Generation Topping(New)"}},{"node":{"path":"/custom-template/loop-conditional-statement/","title":"Loop & Conditional Statement"}},{"node":{"path":"/custom-template/global-helper/","title":"Global Helper"}},{"node":{"path":"/custom-template/designing-template/","title":"Developing Custom Template"}},{"node":{"path":"/custom-template/helper/","title":"Helper"}},{"node":{"path":"/custom-template/custom-template/","title":"Custom Template Objects"}},{"node":{"path":"/contact/question/","title":"CONTACT"}},{"node":{"path":"/business/","title":"Eventstorming - Shopping Mall"}},{"node":{"path":"/business/eventstorming-fooddelivery/","title":"[이벤트스토밍] - DDD Food Delivery 예제"}},{"node":{"path":"/business/ddd-google-drive/","title":"[이벤트스토밍] - 구글 드라이브 예제"}}]}},"context":{}}